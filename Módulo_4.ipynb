{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9D2H69vhwxM3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmHpyoLCxAf7",
    "outputId": "a6c3f79a-002d-4a37-a635-deb8064440c2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dT4LEHAfxNRR"
   },
   "outputs": [],
   "source": [
    "#Adicione o caminho do seu arquivo aqui.\n",
    "file = \"/content/drive/My Drive/Colab Notebooks/USA_Housing.csv\"\n",
    "input_df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxF4srEGTBt3",
    "outputId": "f79fd27a-1a28-467f-aca4-89bab785f732"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SZeUCW6UzoC-"
   },
   "outputs": [],
   "source": [
    "class MachineLearningPipeline:\n",
    "  def __init__(self,df):\n",
    "    self.df = df\n",
    "  \n",
    "  def dataCleaning(self):\n",
    "    self.df.dropna()\n",
    "\n",
    "    \n",
    "  def selectColumns(self):\n",
    "    self.X = self.df[['Avg. Area Income', 'Avg. Area House Age',\\\n",
    "                     'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', \\\n",
    "                     'Area Population']].values\n",
    "    self.y = self.df['Price'].values\n",
    "\n",
    "  def selectColumnsDF(self):\n",
    "    self.df['Avg. Area Income'] = np.log(self.df['Avg. Area Income'])\n",
    "    self.df['Avg. Area House Age'] = np.log(self.df['Avg. Area House Age'])\n",
    "    self.df['Avg. Area Number of Rooms']  = np.log(self.df['Avg. Area Number of Rooms'])\n",
    "    self.df['Avg. Area Number of Bedrooms']  = np.log(self.df['Avg. Area Number of Bedrooms'])\n",
    "    self.df['Area Population']  = np.log(self.df['Area Population'])\n",
    "    self.df = self.df[['Avg. Area Income', 'Avg. Area House Age',\\\n",
    "                     'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', \\\n",
    "                     'Area Population','Price']].values\n",
    "  \n",
    "\n",
    "  def selectColumn(self):\n",
    "    self.X = self.df['Avg. Area Income'].values\n",
    "    self.y = self.df['Price'].values\n",
    "    \n",
    "  \n",
    "  def trainTestSplit(self):\n",
    "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AbzwRbvG35Iz"
   },
   "outputs": [],
   "source": [
    "pipeline = MachineLearningPipeline(input_df)\n",
    "pipeline.dataCleaning()\n",
    "pipeline.selectColumn()\n",
    "pipeline.trainTestSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r8XbD5y1baII"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(y, y_pred):\n",
    "  N = len(y)\n",
    "  error = (1/N) * np.sum(abs(y-y_pred))\n",
    "  return error\n",
    "\n",
    "def mean_squared_error(y, y_pred):\n",
    "  N = len(y)\n",
    "  error = (1/N) * (np.sum(np.array(y-y_pred))** 2)\n",
    "  return error\n",
    "\n",
    "def root_mean_squared_error(y, y_pred):\n",
    "  N = len(y)\n",
    "  error = np.sqrt((1/N) * np.sum((y-y_pred)** 2))\n",
    "  return error\n",
    "\n",
    "def r_squared(y, y_pred):\n",
    "  yhat = y_pred                    \n",
    "  ybar = np.sum(y)/len(y)          \n",
    "  ssreg = np.sum((yhat-ybar)**2)\n",
    "  sstot = np.sum((y - ybar)**2)\n",
    "  error = 1 - (ssreg / sstot)\n",
    "  return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd9faLdu7XSF"
   },
   "source": [
    "# Perceptron & Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcDo16l_gWGP"
   },
   "source": [
    "https://medium.com/@a.mirzaei69/implement-a-neural-network-from-scratch-with-python-numpy-backpropagation-e82b70caa9bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-5zo6gg1LgI",
    "outputId": "5e75d68d-06aa-4a51-9c2f-a4755d971438"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class NeuralNetwork(object):\n",
    "  def __init__(self, layers = [2 , 10, 1], activations=['sigmoid', 'sigmoid']):\n",
    "      assert(len(layers) == len(activations)+1)\n",
    "      self.layers = layers\n",
    "      self.activations = activations\n",
    "      self.weights = []\n",
    "      self.biases = []\n",
    "      for i in range(len(layers)-1):\n",
    "          self.weights.append(np.random.randn(layers[i+1], layers[i]))\n",
    "          self.biases.append(np.random.randn(layers[i+1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def feedforward(self, x):\n",
    "      # return the feedforward value for x\n",
    "      a = np.copy(x)\n",
    "      z_s = []\n",
    "      a_s = [a]\n",
    "      for i in range(len(self.weights)):\n",
    "          activation_function = self.getActivationFunction(self.activations[i])\n",
    "          z_s.append(self.weights[i].dot(a) + self.biases[i])\n",
    "          a = activation_function(z_s[-1])\n",
    "          a_s.append(a)\n",
    "      return (z_s, a_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def backpropagation(self,y, z_s, a_s):\n",
    "        dw = []  # dC/dW\n",
    "        db = []  # dC/dB\n",
    "        deltas = [None] * len(self.weights)  # delta = dC/dZ  known as error for each layer\n",
    "        # insert the last layer error\n",
    "        deltas[-1] = ((y-a_s[-1])*(self.getDerivitiveActivationFunction(self.activations[-1]))(z_s[-1]))\n",
    "        # Perform BackPropagation\n",
    "        for i in reversed(range(len(deltas)-1)):\n",
    "            deltas[i] = self.weights[i+1].T.dot(deltas[i+1])*(self.getDerivitiveActivationFunction(self.activations[i])(z_s[i]))        \n",
    "        #a= [print(d.shape) for d in deltas]\n",
    "        batch_size = y.shape[1]\n",
    "        db = [d.dot(np.ones((batch_size,1)))/float(batch_size) for d in deltas]\n",
    "        dw = [d.dot(a_s[i].T)/float(batch_size) for i,d in enumerate(deltas)]\n",
    "        # return the derivitives respect to weight matrix and biases\n",
    "        return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def train(self, x, y, batch_size=10, epochs=100, lr = 0.01):\n",
    "  # update weights and biases based on the output\n",
    "      for e in range(epochs): \n",
    "          i=0\n",
    "          while(i<len(y)):\n",
    "              x_batch = x[i:i+batch_size]\n",
    "              y_batch = y[i:i+batch_size]\n",
    "              i = i+batch_size\n",
    "              z_s, a_s = self.feedforward(x_batch)\n",
    "              dw, db = self.backpropagation(y_batch, z_s, a_s)\n",
    "              self.weights = [w+lr*dweight for w,dweight in  zip(self.weights, dw)]\n",
    "              self.biases = [w+lr*dbias for w,dbias in  zip(self.biases, db)]\n",
    "              print(\"loss = {}\".format(np.linalg.norm(a_s[-1]-y_batch) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  @staticmethod\n",
    "  def getActivationFunction(name):\n",
    "      if(name == 'sigmoid'):\n",
    "          return lambda x : np.exp(x)/(1+np.exp(x))\n",
    "      elif(name == 'linear'):\n",
    "          return lambda x : x\n",
    "      elif(name == 'relu'):\n",
    "          def relu(x):\n",
    "              y = np.copy(x)\n",
    "              y[y<0] = 0\n",
    "              return y\n",
    "          return relu\n",
    "      else:\n",
    "          print('Unknown activation function. linear is used')\n",
    "          return lambda x: x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "  @staticmethod\n",
    "  def getDerivitiveActivationFunction(name):\n",
    "      if(name == 'sigmoid'):\n",
    "          sig = lambda x : np.exp(x)/(1+np.exp(x))\n",
    "          return lambda x :sig(x)*(1-sig(x)) \n",
    "      elif(name == 'linear'):\n",
    "          return lambda x: 1\n",
    "      elif(name == 'relu'):\n",
    "          def relu_diff(x):\n",
    "              y = np.copy(x)\n",
    "              y[y>=0] = 1\n",
    "              y[y<0] = 0\n",
    "              return y\n",
    "          return relu_diff\n",
    "      else:\n",
    "          print('Unknown activation function. linear is used')\n",
    "          return lambda x: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-59a70423b8d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    nn = NeuralNetwork([1, 100, 1],activations=['sigmoid', 'sigmoid'])\n",
    "    X = np.log(pipeline.X).reshape(1, -1)\n",
    "    y = np.log(pipeline.y).reshape(1, -1)\n",
    "    \n",
    "    nn.train(X, y, epochs=100, batch_size=32, lr = .001)\n",
    "    _, a_s = nn.feedforward(X)\n",
    "\n",
    "    print(mean_absolute_error(y.flatten(), a_s[-1].flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58ntEZ9n7f5d"
   },
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "G02H-DEk7loT",
    "outputId": "26a61f71-2ac8-468e-961c-c4fdc7cb8132"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "msYBEARo7joB"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3PlVzxu8l8p",
    "outputId": "d1affd1a-cde5-44d8-e8bd-02d1075c1ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9XzQAgV_8n7h"
   },
   "outputs": [],
   "source": [
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u463st_98p10"
   },
   "outputs": [],
   "source": [
    "classificador.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classificador.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classificador.add(Flatten())\n",
    "\n",
    "classificador.add(Dense(units = 128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units = 128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuirKpUN8tzc",
    "outputId": "80f4f5f5-2853-4990-f79b-e8f715eed17c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 29, 29, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 829,985\n",
      "Trainable params: 829,857\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classificador.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Oph-MUvs8wTu"
   },
   "outputs": [],
   "source": [
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                      metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d_lTBMbq8ygF"
   },
   "outputs": [],
   "source": [
    "gerador_treinamento = ImageDataGenerator(rescale = 1./255,\n",
    "                                         rotation_range = 7,\n",
    "                                         horizontal_flip = True,\n",
    "                                         shear_range = 0.2,\n",
    "                                         height_shift_range = 0.07,\n",
    "                                         zoom_range = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tgTM9V2H81i_"
   },
   "outputs": [],
   "source": [
    "gerador_teste = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iC-HwrcD834C",
    "outputId": "ec19be76-9f7d-4ce2-c3aa-e757cbcc362f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "file = \"/content/drive/My Drive/Colab Notebooks/dataset/training_set\"\n",
    "\n",
    "base_treinamento = gerador_treinamento.flow_from_directory(file,\n",
    "                                                           target_size = (64, 64),\n",
    "                                                           batch_size = 32,\n",
    "                                                           class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pms1gpt86YB",
    "outputId": "f7264894-270b-4728-b76d-7fcf0853c167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "file = \"/content/drive/My Drive/Colab Notebooks/dataset/test_set\"\n",
    "\n",
    "base_teste = gerador_teste.flow_from_directory(file,\n",
    "                                               target_size = (64, 64),\n",
    "                                               batch_size = 32,\n",
    "                                               class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0u7oMXlI88zN",
    "outputId": "80e7692f-3a5f-4bf9-a3fb-17244860195a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 40/125 [========>.....................] - ETA: 14:53 - loss: 0.8914 - accuracy: 0.5625"
     ]
    }
   ],
   "source": [
    "classificador.fit_generator(base_treinamento, steps_per_epoch = 4000 / 32,\n",
    "                            epochs = 40, validation_data = base_teste,\n",
    "                            validation_steps = 1000 / 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBAyUPt38_AT"
   },
   "outputs": [],
   "source": [
    "imagem_teste = image.load_img('/content/drive/My Drive/Colab Notebooks/dataset/test_set/cachorro/dog.3526.jpg',\n",
    "                              target_size = (64,64))\n",
    "imagem_teste = image.img_to_array(imagem_teste)\n",
    "imagem_teste /= 255\n",
    "imagem_teste = np.expand_dims(imagem_teste, axis = 0)\n",
    "previsao = classificador.predict(imagem_teste)\n",
    "\n",
    "previsao = (previsao > 0.5)\n",
    "\n",
    "previsao"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Módulo 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
